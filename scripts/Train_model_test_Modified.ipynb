{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and do test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess_data import *\n",
    "from Hyperparameter_optimization import *\n",
    "from Degree_selection import *\n",
    "from proj1_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "## Load the training set\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y_train, tX_train, ids_train = load_csv_data(DATA_TRAIN_PATH)\n",
    "feature_names = load_headers(DATA_TRAIN_PATH)\n",
    "\n",
    "# convert y from -1/1 to 0,1\n",
    "y_train = (y_train+1)/2\n",
    "\n",
    "# process train set\n",
    "data_pro  = data_preprocess_train(tX_train,y_train,outlier_method = 'IQR',n_out = 5)\n",
    "\n",
    "## Load the test set\n",
    "\n",
    "# Load test set\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "feature_names = load_headers(DATA_TEST_PATH)\n",
    "# process test set\n",
    "data_test  = data_preprocess_predict(tX_test,outlier_method = 'IQR',n_out = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model and see accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────┐\n",
      "│               Group: 0               │\n",
      "└──────────────────────────────────────┘\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.0001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.28282235045550486 \n",
      " Accuracy: 0.6756471066540182\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.20470258385707538 \n",
      " Accuracy: 0.6728825044043909\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.01 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 1.3766668261415258 \n",
      " Accuracy: 0.5937931969101504\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.1 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 6.916368676217075e+43 \n",
      " Accuracy: 0.5414690337444098\n",
      "════════════════════════════════════════\n",
      "*The optimal hyperparameters*:\n",
      " Model: least_squares_SGD \n",
      " Optimal accuracy: 0.6756471066540182 \n",
      " Optimal lambda_: 0 \n",
      " Optimal gamma: 0.0001 \n",
      " \n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 1               │\n",
      "└──────────────────────────────────────┘\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.0001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.09993595400839413 \n",
      " Accuracy: 0.9402756508422666\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.09123934669448355 \n",
      " Accuracy: 0.938552833078101\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.01 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 1500.961419827954 \n",
      " Accuracy: 0.5820444104134763\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.1 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 3.962423305795313e+30 \n",
      " Accuracy: 0.673353751914242\n",
      "════════════════════════════════════════\n",
      "*The optimal hyperparameters*:\n",
      " Model: least_squares_SGD \n",
      " Optimal accuracy: 0.9402756508422666 \n",
      " Optimal lambda_: 0 \n",
      " Optimal gamma: 0.0001 \n",
      " \n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 2               │\n",
      "└──────────────────────────────────────┘\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.0001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.09394059771850552 \n",
      " Accuracy: 0.6146327522149184\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.10225578674107387 \n",
      " Accuracy: 0.6159902829379823\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.01 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 21.999958332825734 \n",
      " Accuracy: 0.5244784224064019\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.1 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 1.373096665252168e+44 \n",
      " Accuracy: 0.5779794226921977\n",
      "════════════════════════════════════════\n",
      "*The optimal hyperparameters*:\n",
      " Model: least_squares_SGD \n",
      " Optimal accuracy: 0.6159902829379823 \n",
      " Optimal lambda_: 0 \n",
      " Optimal gamma: 0.001 \n",
      " \n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 3               │\n",
      "└──────────────────────────────────────┘\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.0001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.09784267081984196 \n",
      " Accuracy: 0.9067460317460316\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.08833183379405116 \n",
      " Accuracy: 0.9048941798941799\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.01 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 1.3995114953654757 \n",
      " Accuracy: 0.5974867724867725\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.1 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 1.6869082250522687e+36 \n",
      " Accuracy: 0.46878306878306886\n",
      "════════════════════════════════════════\n",
      "*The optimal hyperparameters*:\n",
      " Model: least_squares_SGD \n",
      " Optimal accuracy: 0.9067460317460316 \n",
      " Optimal lambda_: 0 \n",
      " Optimal gamma: 0.0001 \n",
      " \n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 4               │\n",
      "└──────────────────────────────────────┘\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.0001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.25204777519654004 \n",
      " Accuracy: 0.5327117897518721\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.12943457802644331 \n",
      " Accuracy: 0.599001615034503\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.01 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 111.62558193598518 \n",
      " Accuracy: 0.5289237997357217\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.1 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 3.1687026161790486e+63 \n",
      " Accuracy: 0.5155336954925855\n",
      "════════════════════════════════════════\n",
      "*The optimal hyperparameters*:\n",
      " Model: least_squares_SGD \n",
      " Optimal accuracy: 0.599001615034503 \n",
      " Optimal lambda_: 0 \n",
      " Optimal gamma: 0.001 \n",
      " \n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 5               │\n",
      "└──────────────────────────────────────┘\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.0001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.07333734197300103 \n",
      " Accuracy: 0.8709604519774011\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.001 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 0.003654573126342696 \n",
      " Accuracy: 0.8734463276836157\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.01 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 202140493.97969705 \n",
      " Accuracy: 0.48926553672316375\n",
      "────────────────────────────────────────\n",
      "lambda : 0,  gamma: 0.1 \n",
      " \n",
      " Model least_squares_SGD \n",
      " Loss: 1.0130326003458377e+55 \n",
      " Accuracy: 0.6687005649717515\n",
      "════════════════════════════════════════\n",
      "*The optimal hyperparameters*:\n",
      " Model: least_squares_SGD \n",
      " Optimal accuracy: 0.8734463276836157 \n",
      " Optimal lambda_: 0 \n",
      " Optimal gamma: 0.001 \n",
      " \n",
      "\n",
      " * Overall Accuracy = 0.67621\n"
     ]
    }
   ],
   "source": [
    "#data_pro  = data_preprocess_train(tX_train,y_train,outlier_method = 'IQR',n_out = 5)\n",
    "#lambda_ = [1e-2,1e-3,1e-4,1e-5]\n",
    "lambda_ = [0]\n",
    "#lambda_ = np.linspace(1e-3,1e-5,4)\n",
    "gamma_ = np.logspace(-4,-1,4) #np.logspace(-15,-14,2)\n",
    "accuracy_ = []\n",
    "group_size_ = []\n",
    "optimal_lambdas = []\n",
    "degrees = [2, 2, 2, 2, 2, 2]\n",
    "for idx_data,data in enumerate(data_pro):\n",
    "    print('┌'+'─' * 38+'┐')\n",
    "    print('│               Group: %i               │'%idx_data)\n",
    "    print('└'+'─' * 38+'┘')\n",
    "    tx = data[0]\n",
    "  #  tx = np.hstack((build_poly(tx, degrees[idx_data]),np.sin(tx)))\n",
    "    tx = build_poly(tx, degrees[idx_data])\n",
    "    y = data[1]. reshape(-1,1)\n",
    "    initial_w_ = np.zeros((tx.shape[1],1))\n",
    "    optimal_accuracy, optimal_lambda_, optimal_gamma = Hyperparameter_optimization( y, tx,k_fold=5, \n",
    "                                                                                   lambdas=lambda_ , \n",
    "                                                                                   gammas = gamma_, \n",
    "                                                                                   initial_w = initial_w_, \n",
    "                                                                                   max_iters = 100, \n",
    "                                                                                   model = 'least_squares_SGD')\n",
    "                                                                                   #model = 'least_squares')\n",
    "    accuracy_.append(optimal_accuracy)\n",
    "    group_size_.append(len(data[2]))\n",
    "    optimal_lambdas.append(optimal_lambda_)\n",
    "\n",
    "accuracy_all = np.dot(accuracy_,group_size_)/np.sum(group_size_)\n",
    "print('\\n * Overall Accuracy = %.5f'%accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and do prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────┐\n",
      "│               Group: 0               │\n",
      "└──────────────────────────────────────┘\n",
      "The training of Group 0 is over.\n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 1               │\n",
      "└──────────────────────────────────────┘\n",
      "The training of Group 1 is over.\n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 2               │\n",
      "└──────────────────────────────────────┘\n",
      "The training of Group 2 is over.\n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 3               │\n",
      "└──────────────────────────────────────┘\n",
      "The training of Group 3 is over.\n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 4               │\n",
      "└──────────────────────────────────────┘\n",
      "The training of Group 4 is over.\n",
      "┌──────────────────────────────────────┐\n",
      "│               Group: 5               │\n",
      "└──────────────────────────────────────┘\n",
      "The training of Group 5 is over.\n",
      "\n",
      "Training finished! Start do prediction and write to prediction.csv.\n",
      "\n",
      "Prediction finished! Please check corresponding prediction.csv in ../scripts/.\n"
     ]
    }
   ],
   "source": [
    "#from preprocess_data import *\n",
    "\n",
    "#data_pro  = data_preprocess_train(tX_train,y_train,outlier_method = 'IQR',n_out = 5)\n",
    "\n",
    "# Train\n",
    "lambda_ = [6.5e-05,\n",
    " 1e-05,\n",
    " 0.0009,\n",
    " 0.000835,\n",
    " 0.00078,\n",
    " 0.000615]\n",
    "loss_ = [] \n",
    "w_ = []\n",
    "for idx_data,data in enumerate(data_pro):\n",
    "    print('┌'+'─' * 38+'┐')\n",
    "    print('│               Group: %i               │'%idx_data)\n",
    "    print('└'+'─' * 38+'┘')\n",
    "    tx = data[0]\n",
    "    tx = np.hstack((build_poly(tx, degrees[idx_data]),1/(abs(tx)+1e-10),np.sin(tx)))\n",
    "    y = data[1]\n",
    "    initial_w_ = np.ones(tx.shape[1])\n",
    "    loss_temp, w_temp = ridge_regression(y, tx,lambda_[idx_data])\n",
    "    w_.append(w_temp)\n",
    "    print('The training of Group {} is over.'.format(idx_data))\n",
    "#print('\\n * Overall Accuracy = %.4f'%accuracy_all)\n",
    "\n",
    "print('\\nTraining finished! Start do prediction and write to prediction.csv.')\n",
    "\n",
    "# Using trained model to do prediction\n",
    "label_ = []\n",
    "data_size = sum([len(data_test[:,1][i]) for i in range(6)])\n",
    "y_predict = np.zeros(data_size)\n",
    "for idx_data,data in enumerate(data_test):\n",
    "    tx = data[0]\n",
    "    tx = np.hstack((build_poly(tx, degrees[idx_data]),1/(abs(tx)+1e-10),np.sin(tx)))\n",
    "    label_.append(predict_labels(w_[idx_data], tx,model='ridge_regression'))\n",
    "    y_predict[data[1]] = predict_labels(w_[idx_data], tx,model='ridge_regression')\n",
    "\n",
    "create_csv_submission(range(350000,350000+data_size),(y_predict-0.5)*2,'prediction.csv')\n",
    "\n",
    "print('\\nPrediction finished! Please check corresponding prediction.csv in ../scripts/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_pro[1][0]\n",
    "#x = np.hstack((build_poly(x, 5),1/(abs(x)+1e-10),np.sin(x)))\n",
    "#x = np.hstack((build_poly(x, 10),np.sin(x)))\n",
    "x = build_poly(x, 2)\n",
    "y = data_pro[1][1].reshape(-1,1)\n",
    "w = np.zeros((x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, array([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]]))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_squares_GD(y, x, np.array(w), 1000, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.027099261583267392\n",
      "LOSS 0.026648334455768946\n",
      "LOSS 0.026511557983719285\n",
      "LOSS 0.026447758617281887\n",
      "LOSS 0.026409782682899178\n",
      "LOSS 0.02638463178988856\n",
      "LOSS 0.026367133223390432\n",
      "LOSS 0.0263545831239723\n",
      "LOSS 0.026345343151959497\n",
      "LOSS 0.026338352115607117\n",
      "LOSS 0.026332902992812653\n",
      "LOSS 0.026328519017666155\n",
      "LOSS 0.02632487688059673\n",
      "LOSS 0.026321756625332406\n",
      "LOSS 0.0263190082248272\n",
      "LOSS 0.026316529070828588\n",
      "LOSS 0.026314248751367834\n",
      "LOSS 0.026312118737670333\n",
      "LOSS 0.026310105390698533\n",
      "LOSS 0.026308185216083343\n",
      "LOSS 0.027488254466632323\n",
      "LOSS 0.02697101269067271\n",
      "LOSS 0.026849195138512822\n",
      "LOSS 0.0268155821837019\n",
      "LOSS 0.026803259515594056\n",
      "LOSS 0.026796690747412616\n",
      "LOSS 0.02679194988334484\n",
      "LOSS 0.026787939003141404\n",
      "LOSS 0.026784314186658477\n",
      "LOSS 0.02678095272230345\n",
      "LOSS 0.026777803004872074\n",
      "LOSS 0.026774838326223616\n",
      "LOSS 0.026772041513000444\n",
      "LOSS 0.026769399479463708\n",
      "LOSS 0.026766901180586132\n",
      "LOSS 0.026764536793452615\n",
      "LOSS 0.02676229736248189\n",
      "LOSS 0.0267601746274723\n",
      "LOSS 0.026758160927296794\n",
      "LOSS 0.026756249136911613\n",
      "LOSS 0.027182563385638035\n",
      "LOSS 0.026730470363469892\n",
      "LOSS 0.026603171556885442\n",
      "LOSS 0.026552206480487825\n",
      "LOSS 0.02652737192856695\n",
      "LOSS 0.026513557553721655\n",
      "LOSS 0.026504935799388594\n",
      "LOSS 0.026498936176365527\n",
      "LOSS 0.026494339605184224\n",
      "LOSS 0.026490542513135734\n",
      "LOSS 0.026487236333137203\n",
      "LOSS 0.026484258182116343\n",
      "LOSS 0.02648151866267984\n",
      "LOSS 0.02647896617463973\n",
      "LOSS 0.02647656899093189\n",
      "LOSS 0.026474306124704097\n",
      "LOSS 0.026472162602999554\n",
      "LOSS 0.02647012697581561\n",
      "LOSS 0.02646818997374813\n",
      "LOSS 0.026466343764512373\n",
      "LOSS 0.02654759142929642\n",
      "LOSS 0.02622927702108\n",
      "LOSS 0.02615321036496696\n",
      "LOSS 0.026125654447536114\n",
      "LOSS 0.026111785275115686\n",
      "LOSS 0.02610303778788215\n",
      "LOSS 0.02609671724601475\n",
      "LOSS 0.02609176958364163\n",
      "LOSS 0.02608769232786507\n",
      "LOSS 0.0260842059415423\n",
      "LOSS 0.026081138332627703\n",
      "LOSS 0.02607837702919425\n",
      "LOSS 0.026075845928772566\n",
      "LOSS 0.02607349241462994\n",
      "LOSS 0.026071279540958458\n",
      "LOSS 0.026069181019687113\n",
      "LOSS 0.02606717789699277\n",
      "LOSS 0.026065256307474492\n",
      "LOSS 0.026063405939278823\n",
      "LOSS 0.026061618977733375\n",
      "LOSS 0.026733783702699746\n",
      "LOSS 0.02642268140814418\n",
      "LOSS 0.026363167713707773\n",
      "LOSS 0.026344189111979673\n",
      "LOSS 0.026334828697342133\n",
      "LOSS 0.026328911323333756\n",
      "LOSS 0.02632466827955724\n",
      "LOSS 0.026321377703298544\n",
      "LOSS 0.026318668097629398\n",
      "LOSS 0.02631632678659914\n",
      "LOSS 0.026314226792077417\n",
      "LOSS 0.0263122909248765\n",
      "LOSS 0.02631047173919856\n",
      "LOSS 0.026308739751617856\n",
      "LOSS 0.02630707638326805\n",
      "LOSS 0.02630546970027733\n",
      "LOSS 0.026303911834585157\n",
      "LOSS 0.026302397419242493\n",
      "LOSS 0.02630092263762585\n",
      "LOSS 0.02629948464463438\n",
      " Model least_squares_GD \n",
      " Loss: 0.02637837634797502 \n",
      " Accuracy: 0.9432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02637837634797502, 0.9432)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(y, x,5, 0, 1e-10, np.array(w), 20, 'least_squares_GD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
